# kube-prometheus-stack Configuration for hetzner-lab cluster
# Complete observability stack: Prometheus, Grafana, Alertmanager

# Prometheus configuration
prometheus:
  # Ingress for Prometheus UI
  ingress:
    enabled: true
    ingressClassName: traefik
    annotations:
      cert-manager.io/cluster-issuer: letsencrypt-prod
      traefik.ingress.kubernetes.io/router.middlewares: default-authentik@kubernetescrd
    hosts:
      - prometheus.dthackray.com
    tls:
      - secretName: prometheus-tls
        hosts:
          - prometheus.dthackray.com

  prometheusSpec:
    # Retention period for metrics
    retention: 30d

    # Storage configuration
    storageSpec:
      volumeClaimTemplate:
        spec:
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 50Gi

    # Resource limits
    resources:
      requests:
        cpu: 200m
        memory: 512Mi
      limits:
        cpu: 1000m
        memory: 2Gi

    # Enable ServiceMonitor auto-discovery
    serviceMonitorSelectorNilUsesHelmValues: false
    podMonitorSelectorNilUsesHelmValues: false
    ruleSelectorNilUsesHelmValues: false

    # Scrape all namespaces
    serviceMonitorNamespaceSelector: {}
    podMonitorNamespaceSelector: {}

# Grafana configuration
grafana:
  enabled: true

  # Ingress configuration
  ingress:
    enabled: true
    ingressClassName: traefik
    annotations:
      cert-manager.io/cluster-issuer: letsencrypt-prod
      traefik.ingress.kubernetes.io/router.middlewares: default-authentik@kubernetescrd
    hosts:
      - grafana.dthackray.com
    tls:
      - secretName: grafana-tls
        hosts:
          - grafana.dthackray.com

  # Disable Grafana authentication - using Authentik instead
  grafana.ini:
    auth:
      disable_login_form: true
      disable_signout_menu: true
    auth.basic:
      enabled: true  # Allow basic auth for API access (needed for sidecar reload)
    auth.proxy:
      enabled: true
      header_name: X-authentik-username
      header_property: username
      auto_sign_up: true
      enable_login_token: false
    users:
      auto_assign_org: true
      auto_assign_org_role: Admin  # All Authentik users get Admin role in Grafana

  # Persistence for dashboards
  persistence:
    enabled: true
    size: 10Gi

  # Additional datasources - Loki and Tempo for LGTM stack
  additionalDataSources:
    - name: Loki
      type: loki
      uid: loki
      url: http://loki-gateway.loki.svc.cluster.local
      access: proxy
      jsonData:
        maxLines: 1000
        derivedFields:
          - name: TraceID
            datasourceUid: tempo
            matcherRegex: "traceID=(\\w+)"
            url: "$${__value.raw}"

    - name: Tempo
      type: tempo
      uid: tempo
      url: http://tempo.tempo.svc.cluster.local:3100
      access: proxy
      jsonData:
        httpMethod: GET
        tracesToLogsV2:
          datasourceUid: loki
          spanStartTimeShift: "-1h"
          spanEndTimeShift: "1h"
          filterByTraceID: true
          filterBySpanID: false
        tracesToMetrics:
          datasourceUid: prometheus
          spanStartTimeShift: "-1h"
          spanEndTimeShift: "1h"
        serviceMap:
          datasourceUid: prometheus
        nodeGraph:
          enabled: true
        lokiSearch:
          datasourceUid: loki

  # Resource limits
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 512Mi

  # Sidecar configuration for datasources
  sidecar:
    datasources:
      enabled: true
      skipReload: false

# Alertmanager configuration
alertmanager:
  # Ingress for Alertmanager UI
  ingress:
    enabled: true
    ingressClassName: traefik
    annotations:
      cert-manager.io/cluster-issuer: letsencrypt-prod
      traefik.ingress.kubernetes.io/router.middlewares: default-authentik@kubernetescrd
    hosts:
      - alertmanager.dthackray.com
    tls:
      - secretName: alertmanager-tls
        hosts:
          - alertmanager.dthackray.com

  alertmanagerSpec:
    # Storage for alert state
    storage:
      volumeClaimTemplate:
        spec:
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 10Gi

    # Resource limits
    resources:
      requests:
        cpu: 50m
        memory: 128Mi
      limits:
        cpu: 200m
        memory: 256Mi

# Node exporter - metrics from cluster nodes
prometheus-node-exporter:
  resources:
    requests:
      cpu: 50m
      memory: 64Mi
    limits:
      cpu: 200m
      memory: 128Mi

# kube-state-metrics - metrics about Kubernetes objects
kube-state-metrics:
  resources:
    requests:
      cpu: 50m
      memory: 64Mi
    limits:
      cpu: 200m
      memory: 128Mi

# Default monitoring targets
defaultRules:
  create: true
  rules:
    alertmanager: true
    etcd: true
    configReloaders: true
    general: true
    k8s: true
    kubeApiserverAvailability: true
    kubeApiserverSlos: true
    kubelet: true
    kubeProxy: true
    kubePrometheusGeneral: true
    kubePrometheusNodeRecording: true
    kubernetesApps: true
    kubernetesResources: true
    kubernetesStorage: true
    kubernetesSystem: true
    kubeScheduler: true
    kubeStateMetrics: true
    network: true
    node: true
    nodeExporterAlerting: true
    nodeExporterRecording: true
    prometheus: true
    prometheusOperator: true
