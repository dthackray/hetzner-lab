# Kafka Cluster with KRaft mode (no ZooKeeper)
# Reference: https://strimzi.io/docs/operators/latest/deploying
---
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaNodePool
metadata:
  name: combined
  labels:
    strimzi.io/cluster: kafka-cluster
spec:
  replicas: 3
  # Combined role: both broker and controller
  roles:
    - controller
    - broker
  storage:
    type: persistent-claim
    size: 20Gi
    deleteClaim: false
  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: 1000m
      memory: 2Gi
---
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: kafka-cluster
  annotations:
    strimzi.io/kraft: "enabled"
    strimzi.io/node-pools: "enabled"
spec:
  kafka:
    version: 4.1.1
    # Metadata version for KRaft
    metadataVersion: "4.1"
    listeners:
      - name: plain
        port: 9092
        type: internal
        tls: false
      - name: tls
        port: 9093
        type: internal
        tls: true
    config:
      # Default replication factors
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
      default.replication.factor: 3
      min.insync.replicas: 2
      # Log retention
      log.retention.hours: 168
      log.retention.bytes: 10737418240
    metricsConfig:
      type: jmxPrometheusExporter
      valueFrom:
        configMapKeyRef:
          name: kafka-metrics
          key: kafka-metrics-config.yml
  # No MSK config - using node pools instead
  entityOperator:
    topicOperator:
      resources:
        requests:
          cpu: 100m
          memory: 256Mi
        limits:
          cpu: 500m
          memory: 512Mi
    userOperator:
      resources:
        requests:
          cpu: 100m
          memory: 256Mi
        limits:
          cpu: 500m
          memory: 512Mi
---
# Prometheus JMX metrics configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka-metrics
data:
  kafka-metrics-config.yml: |
    lowercaseOutputName: true
    lowercaseOutputLabelNames: true
    rules:
      # Kafka broker metrics
      - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+), topic=(.+), partition=(.*)><>Value
        name: kafka_server_$1_$2
        type: GAUGE
        labels:
          clientId: "$3"
          topic: "$4"
          partition: "$5"
      - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+), brokerHost=(.+), brokerPort=(.+)><>Value
        name: kafka_server_$1_$2
        type: GAUGE
        labels:
          clientId: "$3"
          broker: "$4:$5"
      - pattern: kafka.server<type=(.+), name=(.+)><>Value
        name: kafka_server_$1_$2
        type: GAUGE
      - pattern: kafka.server<type=(.+), name=(.+)><>Count
        name: kafka_server_$1_$2_total
        type: COUNTER
      # Controller metrics
      - pattern: kafka.controller<type=(.+), name=(.+)><>Value
        name: kafka_controller_$1_$2
        type: GAUGE
      - pattern: kafka.controller<type=(.+), name=(.+)><>Count
        name: kafka_controller_$1_$2_total
        type: COUNTER
      # Network metrics
      - pattern: kafka.network<type=(.+), name=(.+), request=(.+), error=(.+)><>Count
        name: kafka_network_$1_$2_total
        type: COUNTER
        labels:
          request: "$3"
          error: "$4"
      - pattern: kafka.network<type=(.+), name=(.+), request=(.+)><>Count
        name: kafka_network_$1_$2_total
        type: COUNTER
        labels:
          request: "$3"
      - pattern: kafka.network<type=(.+), name=(.+)><>Value
        name: kafka_network_$1_$2
        type: GAUGE
      # Log metrics
      - pattern: kafka.log<type=(.+), name=(.+), topic=(.+), partition=(.+)><>Value
        name: kafka_log_$1_$2
        type: GAUGE
        labels:
          topic: "$3"
          partition: "$4"
